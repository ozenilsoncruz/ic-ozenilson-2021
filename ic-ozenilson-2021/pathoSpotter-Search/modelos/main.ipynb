{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0e4f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.applications import vgg16, inception_v3, resnet_v2, xception\n",
    "from keras.callbacks import (EarlyStopping, ModelCheckpoint)\n",
    "from keras.layers import (Dense, Dropout, GlobalMaxPool2D, Input)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.utils import np_utils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf4f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow:  2.9.1\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 15:06:03.775482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-11 15:06:03.813829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-11 15:06:03.814707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow: \",tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867eecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_class_quantzities(path):\n",
    "    '''\n",
    "    Metodo que define a quantidade de itens de cada classe considerando as subpastas\n",
    "    '''\n",
    "    quantities= {}\n",
    "    \n",
    "    for root, dirs, files in os.walk(path, topdown=False):\n",
    "        for name in dirs:\n",
    "            diretorio = os.path.join(root, name)\n",
    "            dpath, ddirs, dfiles = next(os.walk(diretorio))\n",
    "            sub = root.replace(path, '').split('/')\n",
    "            if len(sub) > 1:\n",
    "                if quantities.get(sub[1]):\n",
    "                    quantities[sub[1]] += len(dfiles)\n",
    "                else:\n",
    "                    quantities[sub[1]] = len(dfiles)\n",
    "            else:\n",
    "                if quantities.get(name):\n",
    "                    quantities[name] += len(dfiles)\n",
    "                else:\n",
    "                    quantities[name] = len(dfiles)\n",
    "            \n",
    "    return quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ef43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_x(model):\n",
    "    model.trainable = False\n",
    "    \n",
    "    x = model.output\n",
    "    x = GlobalMaxPool2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    predictions = Dense(24, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=model.input, outputs=predictions)\n",
    "    model.compile(optimizer=adam_v2.Adam(learning_rate=0.00001, decay=0.0001), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=[tf.keras.metrics.CategoricalAccuracy(),\n",
    "                           tf.keras.metrics.Recall(),\n",
    "                           tf.keras.metrics.Precision(),\n",
    "                           tf.keras.metrics.AUC()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb037aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(base_dir, classes, dim):\n",
    "    X = []\n",
    "    Y = []\n",
    "    processed_image_count = 0\n",
    "    for root, subdirs, files in os.walk(base_dir):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            suffix = file_path[len(base_dir):].lstrip(os.sep)\n",
    "            label = suffix.split(os.sep)[0]\n",
    "            \n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize(dim)\n",
    "            img = img.convert('RGB')\n",
    "            img = np.asarray(img)\n",
    "            \n",
    "            img = img/255.\n",
    "            \n",
    "            X.append(img)\n",
    "            Y.append(classes.index(label))\n",
    "            processed_image_count += 1\n",
    "\n",
    "    print (f\"Imagens processadas: {processed_image_count}\")\n",
    "    \n",
    "    X = np.array(X, dtype='float32')\n",
    "    Y = np.array(Y) #Atrinui o número de classes a Y\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02086194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qtdImages(path, classes, dim, qtd_imgs):\n",
    "    X = []\n",
    "    Y = []\n",
    "    processed_image_count = 0\n",
    "    for root, dirs, files in os.walk(path, topdown=False):\n",
    "        for name in dirs:\n",
    "            diretorio = os.path.join(root, name)\n",
    "            dpath, ddirs, dfiles = next(os.walk(diretorio))\n",
    "            for i in range(qtd_imgs):\n",
    "                if len(dfiles) <= i:\n",
    "                    break\n",
    "                file_path = os.path.join(diretorio, dfiles[i])\n",
    "                suffix = file_path[len(path):].lstrip(os.sep)\n",
    "                label = suffix.split(os.sep)[0]\n",
    "\n",
    "                img = Image.open(file_path)\n",
    "                img = img.resize(dim)\n",
    "                img = img.convert('RGB')\n",
    "                img = np.asarray(img)\n",
    "\n",
    "                img = img/255.\n",
    "\n",
    "                X.append(img)\n",
    "                Y.append(classes.index(label))\n",
    "                processed_image_count += 1\n",
    "\n",
    "    print (f\"Imagens processadas: {processed_image_count}\") \n",
    "    \n",
    "    X = np.array(X, dtype='float32')\n",
    "    Y = np.array(Y) #Atrinui o número de classes a Y\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53488c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_atual = os.getcwd()\n",
    "path_models = path_atual.replace('/'+path_atual.split('/')[-1], '')+'/modelos/save_models/'\n",
    "path_db = path_atual.replace('/'+path_atual.split('/')[-1], '').replace('/'+path_atual.split('/')[-2], '')+'/dataset/kimia/'\n",
    "\n",
    "quantidade = set_class_quantzities(path_db)\n",
    "classes = list(quantidade.keys())\n",
    "\n",
    "metrics = pd.DataFrame(index=['accuracy', 'loss', 'val_accuracy', 'val_loss', 'precision', 'recall', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618ccf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicia as redes do ImageNet\n",
    "vgg16_model = vgg16.VGG16(weights='imagenet', \n",
    "                          include_top=False, \n",
    "                          input_tensor=Input(shape=( 224, 224, 3)), \n",
    "                          input_shape=( 224, 224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f15bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {'vgg16': vgg16_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregamento da Base de dados\n",
    "print(\"Carregando dataset com imagens de dimensao 299x299...\")\n",
    "start = time.time()\n",
    "\n",
    "#dataset com dimensao 224x224\n",
    "x_train, y_train = load_qtdImages(path_db+'train', classes, (224, 224), 150)\n",
    "\n",
    "print(f\"Dataset carregado em: {time.time()-start:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d58df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregamento da Base de dados\n",
    "print(\"Carregando dataset com imagens de dimensao 299x299...\")\n",
    "start = time.time()\n",
    "\n",
    "#dataset com dimensao 224x224\n",
    "x_val, y_val = load_qtdImages(path_db+'test', classes, (224, 224), 25)\n",
    "\n",
    "print(f\"Dataset carregado em: {time.time()-start:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in modelos.items():\n",
    "    print(f'Iniciando treinamento do modelo {name}')\n",
    "    \n",
    "    \n",
    "    y_train = np_utils.to_categorical(y_train, 24)\n",
    "    y_val = np_utils.to_categorical(y_val, 24)\n",
    "\n",
    "    \n",
    "    #Definições de parametros de avaliação\n",
    "    checkpoint = ModelCheckpoint(path_models+name+'/'+name+'.h5', monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    earlyStopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, patience=100, verbose=1, mode='auto', baseline=None)\n",
    "    callbacks_list = [checkpoint, earlyStopping]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    model = model_x(model)\n",
    "    history = model.fit(x = x_train, \n",
    "                        y = y_train,\n",
    "                        batch_size=64,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        epochs=150,\n",
    "                        callbacks=callbacks_list)\n",
    "                        \n",
    "    ttt = time.time() - t0\n",
    "    \n",
    "    accuracy = np.array(history.history['categorical_accuracy'])\n",
    "    loss = np.array(history.history['loss'])\n",
    "    val_accuracy = np.array(history.history['val_categorical_accuracy'])\n",
    "    val_loss = np.array(history.history['val_loss'])\n",
    "   \n",
    "    accuracy = sorted(accuracy, key = float)\n",
    "    val_accuracy = sorted(val_accuracy, key = float)\n",
    "    \n",
    "    metrics.loc['time', name] = ttt\n",
    "    metrics.loc['accuracy', name] = accuracy[-1]\n",
    "    metrics.loc['loss', name] = loss[-1]\n",
    "    metrics.loc['val_accuracy', name] = val_accuracy[-1]\n",
    "    metrics.loc['val_loss', name] = val_loss[-1]\n",
    "    \n",
    "    print(\"Tempo de Treinamento: %.2f\" % (ttt))\n",
    "    print(\"Ac: %.2f\" % (accuracy[-1]))\n",
    "    print(\"Acval: %.2f\" % (val_accuracy[-1]))\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['categorical_accuracy'])\n",
    "    plt.plot(history.history['val_categorical_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.legend(['Treinamento', 'Teste'], loc='upper left')\n",
    "    plt.savefig(path_models+name+'/'+name+\"_accuracy.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.legend(['Treinamento', 'Teste'], loc='upper left')\n",
    "    plt.savefig(path_models+name+'/'+name+\"_loss.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    #salvar dataframe\n",
    "    metrics.to_csv(path_models+name+'/dados_train.csv', index=False, sep=';')\n",
    "    \n",
    "    \n",
    "print('Finalizidado!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
